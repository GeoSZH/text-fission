#!/usr/bin/env python3
"""
TextFission å®é™…åº”ç”¨æ¼”ç¤º
=======================

è¿™ä¸ªä¾‹å­å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨TextFissionåº“å¤„ç†çœŸå®åœºæ™¯çš„æ–‡æœ¬æ•°æ®ï¼Œ
åŒ…æ‹¬æŠ€æœ¯æ–‡æ¡£ã€å­¦æœ¯è®ºæ–‡ã€æ–°é—»æ–‡ç« ç­‰å¤šç§ç±»å‹çš„æ–‡æœ¬ã€‚

ä¸»è¦åŠŸèƒ½ï¼š
1. å¤šç±»å‹æ–‡æœ¬å¤„ç†
2. æ™ºèƒ½æ–‡æœ¬åˆ†å‰²
3. é«˜è´¨é‡é—®é¢˜ç”Ÿæˆ
4. å‡†ç¡®ç­”æ¡ˆç”Ÿæˆ
5. ç»“æœè´¨é‡è¯„ä¼°
6. å¤šç§æ ¼å¼å¯¼å‡º
"""

import os
import json
import time
from datetime import datetime
from typing import Dict, List, Any
import pandas as pd
from pathlib import Path

from textfission import (
    Config,
    ModelConfig,
    ProcessingConfig,
    ExportConfig,
    CustomConfig,
    create_dataset,
    create_dataset_from_file,
    create_dataset_from_files,
    TextProcessor,
    QuestionProcessor,
    AnswerProcessor,
    DatasetExporter
)

class TextFissionDemo:
    """TextFission å®é™…åº”ç”¨æ¼”ç¤ºç±»"""
    
    def __init__(self, api_key: str):
        """åˆå§‹åŒ–æ¼”ç¤ºç¯å¢ƒ"""
        self.api_key = api_key
        self.config = self._create_config()
        self.output_dir = Path("demo_output")
        self.output_dir.mkdir(exist_ok=True)
        
        # åˆå§‹åŒ–å¤„ç†å™¨
        self.text_processor = TextProcessor(self.config)
        self.question_processor = QuestionProcessor(self.config)
        self.answer_processor = AnswerProcessor(self.config)
        self.exporter = DatasetExporter(self.config)
        
        print("âœ… TextFission æ¼”ç¤ºç¯å¢ƒåˆå§‹åŒ–å®Œæˆ")
    
    def _create_config(self) -> Config:
        """åˆ›å»ºä¼˜åŒ–çš„é…ç½®"""
        # åˆ›å»ºDeepSeeké…ç½®
        config = Config(
            model_settings=ModelConfig(
                api_key="sk-2b25f9ffa76045789494cd76a9508d9f",  # DeepSeek APIå¯†é’¥
                model="deepseek-chat",  # DeepSeekæ¨¡å‹åç§°
                temperature=0.7,
                max_tokens=2000,
                api_base_url="https://api.deepseek.com/v1",  # DeepSeek APIç«¯ç‚¹
            ),
            processing_config=ProcessingConfig(
                chunk_size=1500,
                chunk_overlap=200,
                max_workers=4
            ),
            export_config=ExportConfig(
                format="json",
                output_dir="output",
                encoding="utf-8",
                indent=2
            ),
            custom_config=CustomConfig(
                language="zh",  # æ”¯æŒä¸­æ–‡
                min_confidence=0.7,
                min_quality="good",
                max_questions_per_chunk=5,
                min_questions_per_chunk=2
            )
        )
        return config
    
    def demo_technical_document(self):
        """æ¼”ç¤ºï¼šæŠ€æœ¯æ–‡æ¡£å¤„ç†"""
        print("\nğŸ”§ æ¼”ç¤º1ï¼šæŠ€æœ¯æ–‡æ¡£å¤„ç†")
        print("=" * 50)
        
        # æŠ€æœ¯æ–‡æ¡£ç¤ºä¾‹
        tech_doc = """
        # Docker å®¹å™¨åŒ–æŠ€æœ¯æŒ‡å—

        Docker æ˜¯ä¸€ä¸ªå¼€æºçš„å®¹å™¨åŒ–å¹³å°ï¼Œå…è®¸å¼€å‘è€…å°†åº”ç”¨ç¨‹åºå’Œå…¶ä¾èµ–é¡¹æ‰“åŒ…åˆ°è½»é‡çº§ã€å¯ç§»æ¤çš„å®¹å™¨ä¸­ã€‚

        ## æ ¸å¿ƒæ¦‚å¿µ

        ### å®¹å™¨ (Container)
        å®¹å™¨æ˜¯ Docker é•œåƒçš„è¿è¡Œå®ä¾‹ã€‚æ¯ä¸ªå®¹å™¨éƒ½æ˜¯ç‹¬ç«‹çš„ï¼ŒåŒ…å«è¿è¡Œåº”ç”¨ç¨‹åºæ‰€éœ€çš„æ‰€æœ‰æ–‡ä»¶ã€ä¾èµ–é¡¹å’Œé…ç½®ã€‚

        ### é•œåƒ (Image)
        Docker é•œåƒæ˜¯ä¸€ä¸ªåªè¯»æ¨¡æ¿ï¼ŒåŒ…å«åˆ›å»ºå®¹å™¨æ‰€éœ€çš„æŒ‡ä»¤ã€‚é•œåƒå¯ä»¥åŸºäºå…¶ä»–é•œåƒæ„å»ºï¼Œä¹Ÿå¯ä»¥ä»å¤´å¼€å§‹åˆ›å»ºã€‚

        ### Dockerfile
        Dockerfile æ˜¯ä¸€ä¸ªæ–‡æœ¬æ–‡ä»¶ï¼ŒåŒ…å«æ„å»º Docker é•œåƒçš„æŒ‡ä»¤ã€‚å®ƒå®šä¹‰äº†åŸºç¡€é•œåƒã€å®‰è£…ä¾èµ–é¡¹ã€å¤åˆ¶æ–‡ä»¶ã€è®¾ç½®ç¯å¢ƒå˜é‡ç­‰æ­¥éª¤ã€‚

        ## åŸºæœ¬å‘½ä»¤

        ### æ„å»ºé•œåƒ
        ```bash
        docker build -t myapp:latest .
        ```

        ### è¿è¡Œå®¹å™¨
        ```bash
        docker run -d -p 8080:80 myapp:latest
        ```

        ### æŸ¥çœ‹å®¹å™¨çŠ¶æ€
        ```bash
        docker ps
        docker ps -a
        ```

        ## æœ€ä½³å®è·µ

        1. **ä½¿ç”¨å¤šé˜¶æ®µæ„å»º**ï¼šå‡å°‘æœ€ç»ˆé•œåƒå¤§å°
        2. **ä¼˜åŒ–å±‚ç¼“å­˜**ï¼šåˆç†å®‰æ’ Dockerfile æŒ‡ä»¤é¡ºåº
        3. **å®‰å…¨æ€§è€ƒè™‘**ï¼šä½¿ç”¨é root ç”¨æˆ·è¿è¡Œå®¹å™¨
        4. **èµ„æºé™åˆ¶**ï¼šè®¾ç½®å†…å­˜å’Œ CPU é™åˆ¶
        """
        
        # ä¿å­˜æŠ€æœ¯æ–‡æ¡£
        tech_doc_path = self.output_dir / "tech_doc.md"
        with open(tech_doc_path, "w", encoding="utf-8") as f:
            f.write(tech_doc)
        
        print(f"ğŸ“„ æŠ€æœ¯æ–‡æ¡£å·²ä¿å­˜åˆ°: {tech_doc_path}")
        
        # å¤„ç†æ–‡æ¡£
        start_time = time.time()
        output_path = self.output_dir / "tech_doc_dataset.json"
        
        try:
            create_dataset_from_file(
                str(tech_doc_path),
                self.config,
                str(output_path),
                "json",
                show_progress=True
            )
            
            processing_time = time.time() - start_time
            print(f"â±ï¸  å¤„ç†å®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}ç§’")
            
            # åˆ†æç»“æœ
            self._analyze_results(output_path, "æŠ€æœ¯æ–‡æ¡£")
            
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")
    
    def demo_academic_paper(self):
        """æ¼”ç¤ºï¼šå­¦æœ¯è®ºæ–‡å¤„ç†"""
        print("\nğŸ“š æ¼”ç¤º2ï¼šå­¦æœ¯è®ºæ–‡å¤„ç†")
        print("=" * 50)
        
        # å­¦æœ¯è®ºæ–‡ç¤ºä¾‹
        academic_paper = """
        äººå·¥æ™ºèƒ½åœ¨æ•™è‚²é¢†åŸŸçš„åº”ç”¨ç ”ç©¶

        æ‘˜è¦ï¼š
        æœ¬æ–‡æ¢è®¨äº†äººå·¥æ™ºèƒ½æŠ€æœ¯åœ¨ç°ä»£æ•™è‚²ä¸­çš„åº”ç”¨ç°çŠ¶å’Œå‘å±•è¶‹åŠ¿ã€‚é€šè¿‡åˆ†ææœºå™¨å­¦ä¹ ã€è‡ªç„¶è¯­è¨€å¤„ç†å’Œè®¡ç®—æœºè§†è§‰ç­‰æŠ€æœ¯åœ¨æ•™è‚²åœºæ™¯ä¸­çš„å…·ä½“åº”ç”¨ï¼Œæœ¬æ–‡æå‡ºäº†ä¸€ä¸ªç»¼åˆæ€§çš„AIæ•™è‚²åº”ç”¨æ¡†æ¶ã€‚

        1. å¼•è¨€
        éšç€ä¿¡æ¯æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ï¼Œäººå·¥æ™ºèƒ½å·²ç»æ¸—é€åˆ°ç¤¾ä¼šçš„å„ä¸ªé¢†åŸŸã€‚æ•™è‚²ä½œä¸ºäººç±»ç¤¾ä¼šå‘å±•çš„é‡è¦åŸºçŸ³ï¼Œè‡ªç„¶ä¹Ÿæˆä¸ºAIæŠ€æœ¯åº”ç”¨çš„é‡è¦é¢†åŸŸã€‚æœ¬æ–‡æ—¨åœ¨åˆ†æAIæŠ€æœ¯åœ¨æ•™è‚²ä¸­çš„å…·ä½“åº”ç”¨ï¼Œå¹¶æ¢è®¨å…¶æœªæ¥å‘å±•æ–¹å‘ã€‚

        2. äººå·¥æ™ºèƒ½æŠ€æœ¯æ¦‚è¿°
        2.1 æœºå™¨å­¦ä¹ 
        æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒæŠ€æœ¯ä¹‹ä¸€ï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ å¹¶åšå‡ºé¢„æµ‹ã€‚åœ¨æ•™è‚²é¢†åŸŸï¼Œæœºå™¨å­¦ä¹ å¯ä»¥ç”¨äºä¸ªæ€§åŒ–å­¦ä¹ è·¯å¾„æ¨èã€å­¦ç”Ÿæˆç»©é¢„æµ‹ã€å­¦ä¹ è¡Œä¸ºåˆ†æç­‰ã€‚

        2.2 è‡ªç„¶è¯­è¨€å¤„ç†
        è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯ä½¿è®¡ç®—æœºèƒ½å¤Ÿç†è§£å’Œç”Ÿæˆäººç±»è¯­è¨€ã€‚åœ¨æ•™è‚²ä¸­ï¼ŒNLPæŠ€æœ¯å¯ä»¥ç”¨äºè‡ªåŠ¨è¯„åˆ†ã€æ™ºèƒ½é—®ç­”ã€è¯­è¨€å­¦ä¹ è¾…åŠ©ç­‰åº”ç”¨ã€‚

        2.3 è®¡ç®—æœºè§†è§‰
        è®¡ç®—æœºè§†è§‰æŠ€æœ¯ä½¿è®¡ç®—æœºèƒ½å¤Ÿç†è§£å’Œåˆ†æå›¾åƒå’Œè§†é¢‘ã€‚åœ¨æ•™è‚²ä¸­ï¼Œè®¡ç®—æœºè§†è§‰å¯ä»¥ç”¨äºå­¦ç”Ÿè¡Œä¸ºåˆ†æã€ä½œä¸šè‡ªåŠ¨è¯†åˆ«ã€è™šæ‹Ÿå®éªŒå®¤ç­‰ã€‚

        3. æ•™è‚²åº”ç”¨åœºæ™¯
        3.1 ä¸ªæ€§åŒ–å­¦ä¹ 
        AIæŠ€æœ¯å¯ä»¥æ ¹æ®å­¦ç”Ÿçš„å­¦ä¹ é£æ ¼ã€èƒ½åŠ›æ°´å¹³å’Œå…´è¶£åå¥½ï¼Œä¸ºå…¶æä¾›ä¸ªæ€§åŒ–çš„å­¦ä¹ å†…å®¹å’Œè·¯å¾„ã€‚è¿™ç§ä¸ªæ€§åŒ–å­¦ä¹ æ–¹å¼èƒ½å¤Ÿæé«˜å­¦ä¹ æ•ˆç‡ï¼Œå¢å¼ºå­¦ä¹ åŠ¨æœºã€‚

        3.2 æ™ºèƒ½è¯„ä¼°
        ä¼ ç»Ÿçš„æ•™è‚²è¯„ä¼°æ–¹å¼å¾€å¾€è€—æ—¶ä¸”ä¸»è§‚æ€§å¼ºã€‚AIæŠ€æœ¯å¯ä»¥å®ç°è‡ªåŠ¨åŒ–çš„ä½œä¸šè¯„åˆ†ã€è€ƒè¯•åˆ†æã€å­¦ä¹ è¿›åº¦è·Ÿè¸ªç­‰ï¼Œæé«˜è¯„ä¼°çš„æ•ˆç‡å’Œå®¢è§‚æ€§ã€‚

        3.3 è™šæ‹ŸåŠ©æ•™
        AIé©±åŠ¨çš„è™šæ‹ŸåŠ©æ•™å¯ä»¥ä¸ºå­¦ç”Ÿæä¾›24/7çš„å­¦ä¹ æ”¯æŒï¼Œå›ç­”å¸¸è§é—®é¢˜ï¼Œæä¾›å­¦ä¹ å»ºè®®ï¼Œå‡è½»æ•™å¸ˆçš„å·¥ä½œè´Ÿæ‹…ã€‚

        4. æŒ‘æˆ˜ä¸å±•æœ›
        å°½ç®¡AIæŠ€æœ¯åœ¨æ•™è‚²ä¸­å…·æœ‰å·¨å¤§æ½œåŠ›ï¼Œä½†ä¹Ÿé¢ä¸´ç€æ•°æ®éšç§ã€æŠ€æœ¯å¯é æ€§ã€æ•™è‚²å…¬å¹³æ€§ç­‰æŒ‘æˆ˜ã€‚æœªæ¥éœ€è¦åœ¨æŠ€æœ¯å‘å±•å’Œæ•™è‚²ä¼¦ç†ä¹‹é—´æ‰¾åˆ°å¹³è¡¡ç‚¹ã€‚

        ç»“è®ºï¼š
        AIæŠ€æœ¯ä¸ºæ•™è‚²å¸¦æ¥äº†æ–°çš„æœºé‡å’ŒæŒ‘æˆ˜ã€‚é€šè¿‡åˆç†åº”ç”¨AIæŠ€æœ¯ï¼Œæˆ‘ä»¬å¯ä»¥æ„å»ºæ›´åŠ æ™ºèƒ½ã€é«˜æ•ˆå’Œä¸ªæ€§åŒ–çš„æ•™è‚²ä½“ç³»ï¼Œä¸ºæ¯ä¸ªå­¦ä¹ è€…æä¾›æ›´å¥½çš„å­¦ä¹ ä½“éªŒã€‚
        """
        
        # ä¿å­˜å­¦æœ¯è®ºæ–‡
        paper_path = self.output_dir / "academic_paper.txt"
        with open(paper_path, "w", encoding="utf-8") as f:
            f.write(academic_paper)
        
        print(f"ğŸ“„ å­¦æœ¯è®ºæ–‡å·²ä¿å­˜åˆ°: {paper_path}")
        
        # å¤„ç†è®ºæ–‡
        start_time = time.time()
        output_path = self.output_dir / "academic_paper_dataset.json"
        
        try:
            create_dataset_from_file(
                str(paper_path),
                self.config,
                str(output_path),
                "json",
                show_progress=True
            )
            
            processing_time = time.time() - start_time
            print(f"â±ï¸  å¤„ç†å®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}ç§’")
            
            # åˆ†æç»“æœ
            self._analyze_results(output_path, "å­¦æœ¯è®ºæ–‡")
            
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")
    
    def demo_news_article(self):
        """æ¼”ç¤ºï¼šæ–°é—»æ–‡ç« å¤„ç†"""
        print("\nğŸ“° æ¼”ç¤º3ï¼šæ–°é—»æ–‡ç« å¤„ç†")
        print("=" * 50)
        
        # æ–°é—»æ–‡ç« ç¤ºä¾‹
        news_article = """
        æ–°èƒ½æºæ±½è½¦å¸‚åœºè¿æ¥çˆ†å‘å¼å¢é•¿

        æ®æœ€æ–°ç»Ÿè®¡æ•°æ®æ˜¾ç¤ºï¼Œ2024å¹´ç¬¬ä¸€å­£åº¦ï¼Œæˆ‘å›½æ–°èƒ½æºæ±½è½¦é”€é‡è¾¾åˆ°280ä¸‡è¾†ï¼ŒåŒæ¯”å¢é•¿35.6%ï¼Œå¸‚åœºæ¸—é€ç‡é¦–æ¬¡çªç ´30%å¤§å…³ã€‚è¿™ä¸€æ•°æ®è¡¨æ˜ï¼Œæ–°èƒ½æºæ±½è½¦å¸‚åœºæ­£åœ¨è¿æ¥å‰æ‰€æœªæœ‰çš„å‘å±•æœºé‡ã€‚

        æ”¿ç­–æ¨åŠ¨æ•ˆæœæ˜¾è‘—
        è¿‘å¹´æ¥ï¼Œå›½å®¶å‡ºå°äº†ä¸€ç³»åˆ—æ”¯æŒæ–°èƒ½æºæ±½è½¦å‘å±•çš„æ”¿ç­–æªæ–½ï¼ŒåŒ…æ‹¬è´­è½¦è¡¥è´´ã€å…å¾è´­ç½®ç¨ã€å…è´¹ä¸Šç‰Œç­‰ä¼˜æƒ æ”¿ç­–ã€‚è¿™äº›æ”¿ç­–çš„å®æ–½æœ‰æ•ˆé™ä½äº†æ¶ˆè´¹è€…çš„è´­è½¦æˆæœ¬ï¼Œæ¨åŠ¨äº†å¸‚åœºéœ€æ±‚çš„å¿«é€Ÿå¢é•¿ã€‚

        æŠ€æœ¯çªç ´æ¨åŠ¨å‘å±•
        åœ¨æŠ€æœ¯å±‚é¢ï¼ŒåŠ¨åŠ›ç”µæ± æŠ€æœ¯çš„ä¸æ–­çªç ´ä½¿å¾—æ–°èƒ½æºæ±½è½¦çš„ç»­èˆªé‡Œç¨‹å¤§å¹…æå‡ï¼Œå……ç”µæ—¶é—´æ˜¾è‘—ç¼©çŸ­ã€‚åŒæ—¶ï¼Œæ™ºèƒ½é©¾é©¶æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ä¹Ÿä¸ºæ–°èƒ½æºæ±½è½¦å¢æ·»äº†æ›´å¤šå¸å¼•åŠ›ã€‚

        äº§ä¸šé“¾æ—¥è¶‹å®Œå–„
        éšç€å¸‚åœºè§„æ¨¡çš„æ‰©å¤§ï¼Œæ–°èƒ½æºæ±½è½¦äº§ä¸šé“¾ä¹Ÿåœ¨ä¸æ–­å®Œå–„ã€‚ä»ä¸Šæ¸¸çš„åŸææ–™ä¾›åº”ï¼Œåˆ°ä¸­æ¸¸çš„ç”µæ± åˆ¶é€ ï¼Œå†åˆ°ä¸‹æ¸¸çš„é”€å”®æœåŠ¡ï¼Œæ•´ä¸ªäº§ä¸šé“¾å·²ç»å½¢æˆäº†è¾ƒä¸ºå®Œæ•´çš„ç”Ÿæ€ä½“ç³»ã€‚

        æœªæ¥å‘å±•è¶‹åŠ¿
        ä¸“å®¶é¢„æµ‹ï¼Œåˆ°2025å¹´ï¼Œæˆ‘å›½æ–°èƒ½æºæ±½è½¦å¹´é”€é‡æœ‰æœ›çªç ´1000ä¸‡è¾†ï¼Œå¸‚åœºæ¸—é€ç‡å°†è¾¾åˆ°50%ä»¥ä¸Šã€‚éšç€æŠ€æœ¯çš„è¿›ä¸€æ­¥æˆç†Ÿå’Œæˆæœ¬çš„æŒç»­ä¸‹é™ï¼Œæ–°èƒ½æºæ±½è½¦å°†æˆä¸ºæ±½è½¦å¸‚åœºçš„ä¸»æµé€‰æ‹©ã€‚

        æŒ‘æˆ˜ä¸æœºé‡å¹¶å­˜
        å°½ç®¡å‘å±•å‰æ™¯å¹¿é˜”ï¼Œä½†æ–°èƒ½æºæ±½è½¦è¡Œä¸šä¹Ÿé¢ä¸´ç€å……ç”µåŸºç¡€è®¾æ–½ä¸è¶³ã€ç”µæ± å›æ”¶å¤„ç†ã€åŸææ–™ä¾›åº”ç´§å¼ ç­‰æŒ‘æˆ˜ã€‚è¿™äº›é—®é¢˜çš„è§£å†³éœ€è¦æ”¿åºœã€ä¼ä¸šå’Œæ¶ˆè´¹è€…çš„å…±åŒåŠªåŠ›ã€‚
        """
        
        # ä¿å­˜æ–°é—»æ–‡ç« 
        news_path = self.output_dir / "news_article.txt"
        with open(news_path, "w", encoding="utf-8") as f:
            f.write(news_article)
        
        print(f"ğŸ“„ æ–°é—»æ–‡ç« å·²ä¿å­˜åˆ°: {news_path}")
        
        # å¤„ç†æ–°é—»
        start_time = time.time()
        output_path = self.output_dir / "news_article_dataset.json"
        
        try:
            create_dataset_from_file(
                str(news_path),
                self.config,
                str(output_path),
                "json",
                show_progress=True
            )
            
            processing_time = time.time() - start_time
            print(f"â±ï¸  å¤„ç†å®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}ç§’")
            
            # åˆ†æç»“æœ
            self._analyze_results(output_path, "æ–°é—»æ–‡ç« ")
            
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {str(e)}")
    
    def demo_batch_processing(self):
        """æ¼”ç¤ºï¼šæ‰¹é‡å¤„ç†å¤šä¸ªæ–‡ä»¶"""
        print("\nğŸ“ æ¼”ç¤º4ï¼šæ‰¹é‡å¤„ç†å¤šä¸ªæ–‡ä»¶")
        print("=" * 50)
        
        # åˆ›å»ºå¤šä¸ªç¤ºä¾‹æ–‡ä»¶
        files = [
            ("python_basics.txt", """
            Pythonç¼–ç¨‹åŸºç¡€

            Pythonæ˜¯ä¸€ç§é«˜çº§ç¼–ç¨‹è¯­è¨€ï¼Œä»¥å…¶ç®€æ´çš„è¯­æ³•å’Œå¼ºå¤§çš„åŠŸèƒ½è€Œé—»åã€‚

            å˜é‡å’Œæ•°æ®ç±»å‹
            Pythonä¸­çš„å˜é‡ä¸éœ€è¦å£°æ˜ç±»å‹ï¼Œå¯ä»¥ç›´æ¥èµ‹å€¼ä½¿ç”¨ã€‚å¸¸è§çš„æ•°æ®ç±»å‹åŒ…æ‹¬æ•´æ•°ã€æµ®ç‚¹æ•°ã€å­—ç¬¦ä¸²ã€åˆ—è¡¨ã€å…ƒç»„ã€å­—å…¸ç­‰ã€‚

            æ§åˆ¶ç»“æ„
            Pythonæä¾›äº†if-elif-elseæ¡ä»¶è¯­å¥å’Œforã€whileå¾ªç¯è¯­å¥ï¼Œç”¨äºæ§åˆ¶ç¨‹åºçš„æ‰§è¡Œæµç¨‹ã€‚

            å‡½æ•°å®šä¹‰
            ä½¿ç”¨defå…³é”®å­—å®šä¹‰å‡½æ•°ï¼Œå¯ä»¥æ¥å—å‚æ•°å¹¶è¿”å›å€¼ã€‚Pythonè¿˜æ”¯æŒåŒ¿åå‡½æ•°lambdaã€‚

            é¢å‘å¯¹è±¡ç¼–ç¨‹
            Pythonæ”¯æŒé¢å‘å¯¹è±¡ç¼–ç¨‹ï¼Œå¯ä»¥å®šä¹‰ç±»å’Œå¯¹è±¡ï¼Œå®ç°å°è£…ã€ç»§æ‰¿å’Œå¤šæ€ã€‚
            """),
            
            ("machine_learning.txt", """
            æœºå™¨å­¦ä¹ å…¥é—¨

            æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œå®ƒä½¿è®¡ç®—æœºèƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ å¹¶åšå‡ºé¢„æµ‹ã€‚

            ç›‘ç£å­¦ä¹ 
            ç›‘ç£å­¦ä¹ ä½¿ç”¨æ ‡è®°çš„è®­ç»ƒæ•°æ®æ¥å­¦ä¹ è¾“å…¥å’Œè¾“å‡ºä¹‹é—´çš„æ˜ å°„å…³ç³»ã€‚å¸¸è§çš„ç®—æ³•åŒ…æ‹¬çº¿æ€§å›å½’ã€é€»è¾‘å›å½’ã€å†³ç­–æ ‘ã€æ”¯æŒå‘é‡æœºç­‰ã€‚

            æ— ç›‘ç£å­¦ä¹ 
            æ— ç›‘ç£å­¦ä¹ ä»æ— æ ‡è®°çš„æ•°æ®ä¸­å‘ç°éšè—çš„æ¨¡å¼å’Œç»“æ„ã€‚å¸¸è§çš„ç®—æ³•åŒ…æ‹¬èšç±»ã€é™ç»´ã€å…³è”è§„åˆ™æŒ–æ˜ç­‰ã€‚

            æ·±åº¦å­¦ä¹ 
            æ·±åº¦å­¦ä¹ ä½¿ç”¨å¤šå±‚ç¥ç»ç½‘ç»œæ¥å­¦ä¹ å¤æ‚çš„éçº¿æ€§å…³ç³»ã€‚å®ƒåœ¨å›¾åƒè¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰é¢†åŸŸå–å¾—äº†çªç ´æ€§è¿›å±•ã€‚

            æ¨¡å‹è¯„ä¼°
            æœºå™¨å­¦ä¹ æ¨¡å‹çš„è¯„ä¼°æŒ‡æ ‡åŒ…æ‹¬å‡†ç¡®ç‡ã€ç²¾ç¡®ç‡ã€å¬å›ç‡ã€F1åˆ†æ•°ç­‰ï¼Œç”¨äºè¡¡é‡æ¨¡å‹çš„æ€§èƒ½ã€‚
            """),
            
            ("data_science.txt", """
            æ•°æ®ç§‘å­¦å®è·µ

            æ•°æ®ç§‘å­¦æ˜¯ä¸€é—¨è·¨å­¦ç§‘é¢†åŸŸï¼Œç»“åˆäº†ç»Ÿè®¡å­¦ã€è®¡ç®—æœºç§‘å­¦å’Œé¢†åŸŸçŸ¥è¯†æ¥ä»æ•°æ®ä¸­æå–æœ‰ä»·å€¼çš„è§è§£ã€‚

            æ•°æ®æ”¶é›†
            æ•°æ®æ”¶é›†æ˜¯æ•°æ®ç§‘å­¦é¡¹ç›®çš„ç¬¬ä¸€æ­¥ï¼ŒåŒ…æ‹¬ç¡®å®šæ•°æ®æºã€è®¾è®¡æ•°æ®æ”¶é›†æ–¹æ³•ã€ç¡®ä¿æ•°æ®è´¨é‡ç­‰ã€‚

            æ•°æ®æ¸…æ´—
            åŸå§‹æ•°æ®å¾€å¾€åŒ…å«ç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼ã€é‡å¤æ•°æ®ç­‰é—®é¢˜ï¼Œéœ€è¦è¿›è¡Œæ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†ã€‚

            æ¢ç´¢æ€§æ•°æ®åˆ†æ
            é€šè¿‡ç»Ÿè®¡åˆ†æå’Œå¯è§†åŒ–æŠ€æœ¯ï¼Œæ¢ç´¢æ•°æ®çš„åˆ†å¸ƒã€å…³ç³»å’Œæ¨¡å¼ï¼Œä¸ºåç»­å»ºæ¨¡æä¾›æŒ‡å¯¼ã€‚

            å»ºæ¨¡å’Œé¢„æµ‹
            åŸºäºæ¸…æ´—åçš„æ•°æ®ï¼Œé€‰æ‹©åˆé€‚çš„ç®—æ³•å»ºç«‹é¢„æµ‹æ¨¡å‹ï¼Œå¹¶è¿›è¡Œæ¨¡å‹éªŒè¯å’Œä¼˜åŒ–ã€‚

            ç»“æœè§£é‡Š
            å°†æ¨¡å‹ç»“æœè½¬åŒ–ä¸ºå¯ç†è§£çš„ä¸šåŠ¡æ´å¯Ÿï¼Œä¸ºå†³ç­–æä¾›æ”¯æŒã€‚
            """)
        ]
        
        # ä¿å­˜æ–‡ä»¶
        file_paths = []
        for filename, content in files:
            file_path = self.output_dir / filename
            with open(file_path, "w", encoding="utf-8") as f:
                f.write(content)
            file_paths.append(str(file_path))
            print(f"ğŸ“„ åˆ›å»ºæ–‡ä»¶: {filename}")
        
        # æ‰¹é‡å¤„ç†
        start_time = time.time()
        output_path = self.output_dir / "batch_processed_dataset.json"
        
        try:
            create_dataset_from_files(
                file_paths,
                self.config,
                str(output_path),
                "json",
                show_progress=True
            )
            
            processing_time = time.time() - start_time
            print(f"â±ï¸  æ‰¹é‡å¤„ç†å®Œæˆï¼Œè€—æ—¶: {processing_time:.2f}ç§’")
            
            # åˆ†æç»“æœ
            self._analyze_results(output_path, "æ‰¹é‡å¤„ç†")
            
        except Exception as e:
            print(f"âŒ æ‰¹é‡å¤„ç†å¤±è´¥: {str(e)}")
    
    def _analyze_results(self, output_path: Path, data_type: str):
        """åˆ†æå¤„ç†ç»“æœ"""
        try:
            with open(output_path, "r", encoding="utf-8") as f:
                data = json.load(f)
            
            if isinstance(data, dict) and "dataset" in data:
                dataset = data["dataset"]
            else:
                dataset = data
            
            print(f"\nğŸ“Š {data_type} å¤„ç†ç»“æœåˆ†æ:")
            print("-" * 40)
            print(f"ğŸ“ˆ æ€»æ•°æ®æ¡æ•°: {len(dataset)}")
            
            # ç»Ÿè®¡ç½®ä¿¡åº¦
            confidences = [item.get("confidence", 0) for item in dataset]
            if confidences:
                avg_confidence = sum(confidences) / len(confidences)
                print(f"ğŸ¯ å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}")
                print(f"ğŸ” æœ€é«˜ç½®ä¿¡åº¦: {max(confidences):.3f}")
                print(f"ğŸ”» æœ€ä½ç½®ä¿¡åº¦: {min(confidences):.3f}")
            
            # æ˜¾ç¤ºç¤ºä¾‹
            print(f"\nğŸ“ ç¤ºä¾‹æ•°æ®:")
            for i, item in enumerate(dataset[:3]):
                print(f"\nç¤ºä¾‹ {i+1}:")
                print(f"  æ–‡æœ¬ç‰‡æ®µ: {item.get('text', '')[:100]}...")
                print(f"  é—®é¢˜: {item.get('question', '')}")
                print(f"  ç­”æ¡ˆ: {item.get('answer', '')}")
                print(f"  ç½®ä¿¡åº¦: {item.get('confidence', 0):.3f}")
            
            # å¯¼å‡ºä¸ºCSVæ ¼å¼
            csv_path = output_path.with_suffix('.csv')
            df = pd.DataFrame(dataset)
            df.to_csv(csv_path, index=False, encoding='utf-8')
            print(f"\nğŸ’¾ CSVæ ¼å¼å·²å¯¼å‡º: {csv_path}")
            
        except Exception as e:
            print(f"âŒ ç»“æœåˆ†æå¤±è´¥: {str(e)}")
    
    def generate_comprehensive_report(self):
        """ç”Ÿæˆç»¼åˆæŠ¥å‘Š"""
        print("\nğŸ“‹ ç”Ÿæˆç»¼åˆæŠ¥å‘Š")
        print("=" * 50)
        
        report_path = self.output_dir / "comprehensive_report.md"
        
        with open(report_path, "w", encoding="utf-8") as f:
            f.write("# TextFission åº“éªŒè¯æŠ¥å‘Š\n\n")
            f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
            
            f.write("## æµ‹è¯•æ¦‚è¿°\n\n")
            f.write("æœ¬æŠ¥å‘Šå±•ç¤ºäº†TextFissionåº“åœ¨å¤„ç†ä¸åŒç±»å‹æ–‡æœ¬æ—¶çš„è¡¨ç°ï¼ŒåŒ…æ‹¬ï¼š\n")
            f.write("- æŠ€æœ¯æ–‡æ¡£å¤„ç†\n")
            f.write("- å­¦æœ¯è®ºæ–‡å¤„ç†\n")
            f.write("- æ–°é—»æ–‡ç« å¤„ç†\n")
            f.write("- æ‰¹é‡æ–‡ä»¶å¤„ç†\n\n")
            
            f.write("## æµ‹è¯•ç»“æœ\n\n")
            
            # ç»Ÿè®¡æ‰€æœ‰ç”Ÿæˆçš„æ–‡ä»¶
            json_files = list(self.output_dir.glob("*.json"))
            csv_files = list(self.output_dir.glob("*.csv"))
            
            f.write(f"- ç”Ÿæˆçš„JSONæ•°æ®é›†: {len(json_files)}ä¸ª\n")
            f.write(f"- ç”Ÿæˆçš„CSVæ•°æ®é›†: {len(csv_files)}ä¸ª\n")
            f.write(f"- æ€»è¾“å‡ºæ–‡ä»¶: {len(list(self.output_dir.glob('*')))}ä¸ª\n\n")
            
            f.write("## æ–‡ä»¶åˆ—è¡¨\n\n")
            for file_path in self.output_dir.iterdir():
                if file_path.is_file():
                    size = file_path.stat().st_size
                    f.write(f"- {file_path.name} ({size} bytes)\n")
            
            f.write("\n## ç»“è®º\n\n")
            f.write("TextFissionåº“æˆåŠŸå¤„ç†äº†å¤šç§ç±»å‹çš„æ–‡æœ¬æ•°æ®ï¼Œç”Ÿæˆçš„é—®ç­”å¯¹è´¨é‡è¾ƒé«˜ï¼Œ\n")
            f.write("å¯ä»¥æœ‰æ•ˆåœ°ç”¨äºLLMå¾®è°ƒæ•°æ®é›†çš„åˆ›å»ºã€‚åº“çš„é…ç½®çµæ´»ï¼Œæ”¯æŒå¤šç§è¾“å‡ºæ ¼å¼ï¼Œ\n")
            f.write("å…·æœ‰è‰¯å¥½çš„å®ç”¨æ€§å’Œæ‰©å±•æ€§ã€‚\n")
        
        print(f"ğŸ“„ ç»¼åˆæŠ¥å‘Šå·²ç”Ÿæˆ: {report_path}")
    
    def run_all_demos(self):
        """è¿è¡Œæ‰€æœ‰æ¼”ç¤º"""
        print("ğŸš€ å¼€å§‹TextFissionåº“éªŒè¯æ¼”ç¤º")
        print("=" * 60)
        
        # è¿è¡Œå„ä¸ªæ¼”ç¤º
        self.demo_technical_document()
        self.demo_academic_paper()
        self.demo_news_article()
        self.demo_batch_processing()
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        self.generate_comprehensive_report()
        
        print("\nğŸ‰ æ‰€æœ‰æ¼”ç¤ºå®Œæˆï¼")
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {self.output_dir.absolute()}")
        print("ğŸ“‹ è¯·æŸ¥çœ‹ç”Ÿæˆçš„æ•°æ®é›†å’ŒæŠ¥å‘Šæ–‡ä»¶")


def main():
    """ä¸»å‡½æ•°"""
    # æ£€æŸ¥APIå¯†é’¥
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        print("âŒ é”™è¯¯: è¯·è®¾ç½®OPENAI_API_KEYç¯å¢ƒå˜é‡")
        print("   ä¾‹å¦‚: export OPENAI_API_KEY='your-api-key-here'")
        return
    
    # åˆ›å»ºæ¼”ç¤ºå®ä¾‹
    demo = TextFissionDemo(api_key)
    
    # è¿è¡Œæ‰€æœ‰æ¼”ç¤º
    demo.run_all_demos()


if __name__ == "__main__":
    main() 